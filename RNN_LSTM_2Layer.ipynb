{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM,Dense, Dropout, Embedding, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "# from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "news_data = pd.read_csv(\"/Users/akhilesh/Desktop/news_dataset.csv\")\n",
    "news_data.content=news_data.content.astype(str)\n",
    "X = news_data.content\n",
    "# Name: is_sarcastic, Length: 26709, dtype: int64\n",
    "Y = news_data.label\n",
    "Y = Y.values.reshape(-1, 1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23255 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23255/23255 [==============================] - 97s 4ms/step - loss: 0.2935 - accuracy: 0.8714 - val_loss: 0.4149 - val_accuracy: 0.8390\n",
      "Epoch 2/150\n",
      "23255/23255 [==============================] - 98s 4ms/step - loss: 0.0864 - accuracy: 0.9708 - val_loss: 0.7403 - val_accuracy: 0.8108\n",
      "2872/2872 [==============================] - 3s 998us/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 108s 5ms/step - loss: 0.2911 - accuracy: 0.8754 - val_loss: 0.3528 - val_accuracy: 0.8835\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 103s 4ms/step - loss: 0.0866 - accuracy: 0.9703 - val_loss: 0.4153 - val_accuracy: 0.8634\n",
      "2871/2871 [==============================] - 3s 1ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 105s 5ms/step - loss: 0.2969 - accuracy: 0.8678 - val_loss: 0.4253 - val_accuracy: 0.8398\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 108s 5ms/step - loss: 0.0887 - accuracy: 0.9691 - val_loss: 0.4204 - val_accuracy: 0.8506\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 111s 5ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.8634 - val_accuracy: 0.7914\n",
      "2871/2871 [==============================] - 4s 1ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 107s 5ms/step - loss: 0.2942 - accuracy: 0.8709 - val_loss: 0.4384 - val_accuracy: 0.8533\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 105s 5ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 0.2945 - val_accuracy: 0.8893\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 108s 5ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.8458 - val_accuracy: 0.8011\n",
      "2871/2871 [==============================] - 4s 1ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 117s 5ms/step - loss: 0.3048 - accuracy: 0.8635 - val_loss: 0.4968 - val_accuracy: 0.7763\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 112s 5ms/step - loss: 0.0841 - accuracy: 0.9707 - val_loss: 0.4165 - val_accuracy: 0.8719\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 113s 5ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.7718 - val_accuracy: 0.8297\n",
      "2871/2871 [==============================] - 3s 1ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 116s 5ms/step - loss: 0.3003 - accuracy: 0.8669 - val_loss: 0.5276 - val_accuracy: 0.8084\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 122s 5ms/step - loss: 0.0881 - accuracy: 0.9691 - val_loss: 0.3874 - val_accuracy: 0.8394\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 121s 5ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.6827 - val_accuracy: 0.8301\n",
      "2871/2871 [==============================] - 4s 1ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 123s 5ms/step - loss: 0.3019 - accuracy: 0.8663 - val_loss: 0.5270 - val_accuracy: 0.8115\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 123s 5ms/step - loss: 0.0870 - accuracy: 0.9695 - val_loss: 0.2380 - val_accuracy: 0.8951\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 124s 5ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.7264 - val_accuracy: 0.8270\n",
      "2871/2871 [==============================] - 4s 1ms/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 124s 5ms/step - loss: 0.2916 - accuracy: 0.8705 - val_loss: 0.3436 - val_accuracy: 0.8456\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 125s 5ms/step - loss: 0.0975 - accuracy: 0.9672 - val_loss: 0.6116 - val_accuracy: 0.8065\n",
      "2871/2871 [==============================] - 4s 1ms/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 120s 5ms/step - loss: 0.2921 - accuracy: 0.8705 - val_loss: 0.3200 - val_accuracy: 0.8669\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 114s 5ms/step - loss: 0.0969 - accuracy: 0.9665 - val_loss: 0.3870 - val_accuracy: 0.8642\n",
      "2871/2871 [==============================] - 3s 1ms/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 150, 64)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 150, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,758,145\n",
      "Trainable params: 2,758,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilesh/anaconda3/envs/Black_Hole/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23256 samples, validate on 2584 samples\n",
      "Epoch 1/150\n",
      "23256/23256 [==============================] - 115s 5ms/step - loss: 0.2925 - accuracy: 0.8726 - val_loss: 0.4145 - val_accuracy: 0.8560\n",
      "Epoch 2/150\n",
      "23256/23256 [==============================] - 116s 5ms/step - loss: 0.0964 - accuracy: 0.9667 - val_loss: 0.2848 - val_accuracy: 0.8878\n",
      "Epoch 3/150\n",
      "23256/23256 [==============================] - 115s 5ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.5025 - val_accuracy: 0.8506\n",
      "2871/2871 [==============================] - 3s 1ms/step\n",
      "[0.97080195, 0.97033024, 0.99071205, 0.99221706, 0.99367905, 0.9917871, 0.9912711, 0.96723425, 0.9664603, 0.9853801]\n",
      "[0.8107585310935974, 0.8633900880813599, 0.7914086580276489, 0.8010835647583008, 0.8297213912010193, 0.8301083445549011, 0.8270123600959778, 0.806501567363739, 0.8641641139984131, 0.8506191968917847]\n",
      "[0.902506947517395, 0.9118773937225342, 0.8916753530502319, 0.9136189222335815, 0.9122257232666016, 0.9049111604690552, 0.9101358652114868, 0.909439206123352, 0.9031696319580078, 0.9132706522941589]\n",
      "[0.8733812949640288, 0.8958818958818959, 0.8412138320395202, 0.8807017543859649, 0.888, 0.8768328445747801, 0.8921933085501859, 0.872899926953981, 0.8822205551387847, 0.8986175115207373]\n",
      "[0.921092564491654, 0.9064465408805031, 0.9327073552425665, 0.9414853713428357, 0.9257012888551933, 0.9192928516525749, 0.913937547600914, 0.9328649492583919, 0.9067077872012336, 0.9090909090909091]\n",
      "[0.9039182256177704, 0.9113220821975999, 0.8957322086947296, 0.9154761056974257, 0.913237242365741, 0.9061432411129117, 0.9104347558286983, 0.9117154934971204, 0.9034809584036663, 0.9128787878787878]\n",
      "training accuracy: 0.98198736\n",
      "validation accuracy: 0.8274767816066741\n",
      "test accuracy: 0.9072830855846405\n",
      "Precision: 0.8801942924009879\n",
      "Recall: 0.9209327165616775\n",
      "ROC AUC: 0.908433910129445\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "prec = []\n",
    "recall = []\n",
    "roc = []\n",
    "for train, test in k_fold.split(X, Y):\n",
    "    max_words = 40000\n",
    "    max_length = 150\n",
    "    t = Tokenizer(num_words=max_words)\n",
    "    t.fit_on_texts(X[train])\n",
    "    train_sequence = t.texts_to_sequences(X[train])\n",
    "    train_padded = pad_sequences(train_sequence, maxlen=max_length)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 64, input_length=max_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(64,  return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    histroy = model.fit(train_padded, Y[train], batch_size=100, epochs=150, validation_split=0.1,\n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.00001)])\n",
    "#    histroy = model.fit(train_padded, Y[train], batch_size=100, epochs=25, validation_split=0.1)\n",
    "    train_acc.append(histroy.history['accuracy'][-1])\n",
    "    val_acc.append(histroy.history['val_accuracy'][-1])\n",
    "    test_sequence = t.texts_to_sequences(X[test])\n",
    "    test_padded = pad_sequences(test_sequence, maxlen=max_length)\n",
    "    test_scores = model.evaluate(test_padded, Y[test])\n",
    "    predictions = model.predict_classes(test_padded)\n",
    "    predictions = predictions[:,0]\n",
    "    prec.append(precision_score(Y[test], predictions))\n",
    "    recall.append(recall_score(Y[test], predictions))\n",
    "    roc.append(roc_auc_score(Y[test], predictions))\n",
    "    test_acc.append(test_scores[1])\n",
    "\n",
    "print(train_acc)\n",
    "print(val_acc)\n",
    "print(test_acc)\n",
    "print(prec)\n",
    "print(recall)\n",
    "print(roc)\n",
    "print(\"training accuracy:\", np.mean(train_acc))\n",
    "print(\"validation accuracy:\", np.mean(val_acc))\n",
    "print(\"test accuracy:\", np.mean(test_acc))\n",
    "print(\"Precision:\", np.mean(prec))\n",
    "print(\"Recall:\", np.mean(recall))\n",
    "print(\"ROC AUC:\", np.mean(roc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnwAAAHfCAYAAADKjQWLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd7hcZdWw8XulQUJv0qVGFFR6Rwii9GoDROAFNFQVFRERXhBB+BAb0gzSURAEXpEqgqEoKBFCk94TEloQSAKknPX9sfeB4ZiTnIRzZs7Z+/55zZWZZ+89+5lcDrOy1lMiM5EkSVJ19Wt1ByRJktSzDPgkSZIqzoBPkiSp4gz4JEmSKs6AT5IkqeIM+CRJkipuQKs7oJmb+spTrpsjtcDgpT7V6i5ItTRtytho5v2683d24KIrNrXvs8MMnyRJUsWZ4ZMkSfXVNr3VPWgKAz5JklRf2dbqHjSFJV1JkqSKM8MnSZLqq60eGT4DPkmSVFtpSVeSJElVYIZPkiTVlyVdSZKkirOkK0mSpCowwydJkurLhZclSZIqzpKuJEmSqsAMnyRJqi9n6UqSJFWbCy9LkiSpEszwSZKk+rKkK0mSVHGWdCVJklQFZvgkSVJ9ufCyJElSxVnSlSRJUhWY4ZMkSfXlLF1JkqSKs6QrSZKkKjDDJ0mS6suSriRJUrVluiyLJElStTmGT5IkSVVghk+SJNWXY/gkSZIqzpKuJEmSqsAMnyRJqq82Z+lKkiRVmyVdSZIkVYEZPkmSVF/O0pUkSao4S7qSJEmqAjN8kiSpvizpSpIkVVxNAj5LupIkSRVnhk+SJNVWpgsvS5IkVZslXUmSJFWBGT5JklRfNVmHz4BPkiTVlyVdSZIkVYEZPkmSVF+WdCVJkirOkq4kSZKqwAyfJEmqL0u6kiRJFWdJV5IkSVVghk+SJNVXTTJ8BnySJKm+ajKGz5KuJElSxRnwSZKk+mpr677HLETEshHx14j4d0Q8FBHfLNuPjYixETG6fGzbcM33I+KJiHg0IrZqaN+6bHsiIo6Y1b0t6UqSpPpqbkl3GvCdzLwnIuYD/hURN5XHfp6ZpzSeHBGrArsBqwFLAX+JiI+Uh08HPguMAe6OiKsz89+d3diAT5IkqQkycxwwrnz+ZkQ8DCw9k0t2Ai7NzHeApyPiCWC98tgTmfkUQERcWp7bacBnSVeSJNVXN5Z0I2J4RIxqeAzv7LYRsTywJvCPsumQiLg/Is6NiIXKtqWB5xsuG1O2ddbeKQM+SZJUX9nWbY/MHJGZ6zQ8RszolhExL3AFcGhmvgGcCawErEGRAfxpd39MS7qSJElNEhEDKYK932bmlQCZ+WLD8bOBa8qXY4FlGy5fpmxjJu0zZIZPkiTVV3Nn6QZwDvBwZv6soX3JhtN2AR4sn18N7BYRc0XECsBQ4J/A3cDQiFghIgZRTOy4emb3NsMnSZLqq7k7bWwM7Ak8EBGjy7Yjgd0jYg0ggWeA/QEy86GIuIxiMsY04ODMnA4QEYcANwL9gXMz86GZ3diAT5IkqQky8w4gZnDouplccwJwwgzar5vZdR0Z8EmSpPrKbHUPmsKAT5Ik1VdzS7ot46QNSZKkijPDJ0mS6qsmGT4DPkmSVF/N3Uu3ZSzpSpIkVZwZPkmSVF+WdCVJkiquJsuyWNKVJEmqODN8kiSpvizpSpIkVVxNAj5LupIkSRVnhk+SJNVXTdbhM+CTJEm1lW3O0pUkSVIFmOGTJEn1VZNJGwZ8kiSpvhzDJ0mSVHGO4ZMkSVIVmOGTJEn15Rg+SZKkiqtJwGdJV5IkqeLM8EmSpPrKekzaMOCTJEn1ZUm3b4qI8yPimlb3Q9U07sWX2eeQ77HjHsPZaY/9ueiy/wPgkcefYo/h32KXPQ/k4MOPYeKkSe+/bvxLrPuZXTjvd38A4J13prDbV7/J5/Y+iJ322J/TfnNR0z+L1FedPeKnvDDmPkbfe/P72g8+aB8efOBW7ht9Cyed+AMAFl54If7y58v5z4TH+OUvjm9Fd6VeoSkZvog4H9i7fDkdeAG4FjgyM19rRh8a+rI88DQwAVgxM19vODYSeDAzD2lmn9R3DOjfn+9+/WususrKTJo0mS/t9w02WndNjjnpFxx2yFdZd81PcuU1N3Leb6/g68P3eve6k381gk9tsM67rwcNGsi5p57EkCGDmTptGnsdeBif2mAdVv/4x1rxsaQ+5cILL+OMM87jvPN++W7bsM02YscdtmKttT/LlClTWGyxRQB4++23OebYk1lttY+y2mqrtKrL6s1ch6/b/QVYElge+CqwA3BGE+/f0RDgiBbeX33QYosuzKqrrAzAPPMMYcXlluXFl1/l2efHss4anwBgw3XX4qZb73j3mptv+ztLL7kEK62w3LttEcGQIYMBmDZtGtOmTSMimvhJpL7r9jv+wYTX/vO+tv3334uTf3I6U6ZMAeDll18FYPLkt/jb3+/m7bffaXo/1UdkW/c9erFmBnzvZOb4zByTmX8Gfg9s2XhCRCwQESMi4qWIeDMibo2IdRqOLxIRl0TEmIh4KyIeioh95rA/pwLfjIilOzshCodHxJPl/R6IiK80HL80Is5qeH18RGREbNDQ9nz7NRHxiYi4OSLeiIiJEXFfRGw+h/1Xi40d9yIPP/4kn1xtFVZaYTluuf1OAP7819sZ/+IrQPFjc+7Fl3PQvnv81/XTp0/n83sfzKbb786G667JJ1f7aFP7L1XJ0KErsskm6/H3O/7ELX/5A+usvXqruyT1Ki0ZwxcRKwJbA1Mb2oKizLs0sD2wJnAbcEtELFmeNjdwT3l8NeCXwK8jYos56MblwAPAcTM553hgP+BgYFXgxPJ+25XHRwLDGs4fBrzS3hYRKwPLlOcB/A4YB6wHrAEcC7w9B31Xi02e/Bbf+sHxfO8b+zPvPPPwoyO/xaVXXsOX9v06kya/xcCBxWiJ08+9mD133eXdbF6j/v37c8UFp3PzVRfxwL8f4/Gnnmnyp5CqY8CA/iy00IJstMkOfO+I47nkd2fN+iIJipJudz16sWbO0t06IiYC/SkCN4BvNxzfnCIIWiwz3yrbjo6IHYA9gZMzcyzwk4ZrRkTEp4HdgfeP3u2aw4GbI+JnmflQ44GImKfs35aZeXvZ/HRErEcRAF5LEcidWQakrwPrAv8LfBo4iSLwezIzx5TXLweckpmPlK+fmFGnImI4MBzgjJ8ez1f32n0OPpp6ytRp0zj0B8ez3Zab89lhGwOw4nLLcvYvfgzAM8+N4ba//xOABx56lJv+egc/O+Mc3pw4iYhgrkGD+PIXdnz3/eafb17WW+uT3HHXKIauuHzTP49UBWPHjOP//u96AO4eNZq2tjYWXXRhXnllQot7pt4uazJLt5kB320UQcxg4GvAShRl1XZrU4yre7nDWKa5y3OJiP4U4+52pcgEzgUM4r0M2mzJzFsj4kaKzN2OHQ6vWt77hohoDNsHAs+U1z8SEeMpAruXgScpStVHR8TAsr2xbz8DfhMRe1MEqFc0BH+N/RoBjACY+spTvfufDDWTmfzvib9gxeWWZe/dPvdu+6uv/YdFFlqQtrY2fn3BpXxp520BuPDMU9495/RzLmbI4Ln58hd2ZMJr/2HAgAHMP9+8vP3OO9x5973s+5UvNv3zSFXxx6tvZNiwjRh5698ZOnRFBg0aZLAnNWhmwDc5M9szWt+IiL8CR1OUNaEoL78IfGoG175R/nkY8B3gmxTl2InAj4EPfYB+HQGMjoiO920vd+8APNfh2NSG57dSZCdfAv6amc9ExCsU2b7NgO+3n5iZx0bEb4FtgK2AYyLigMw89wP0X0107/0P8acbbmboSsvz+b0PBuCb++/Ns2Ne4NIri9WAPrPZRuyy3ZYzextefvU1fnD8KUxvayPbkq0+/SmGbbx+j/dfqoKLLzqdzTbdkEUXXZhnnhrFD487hfPOv5TfnP1TRt97M1OmTGXf/Q599/wnHruL+eefl0GDBrHTjluzzXa78/DDj7fwE6hX6eWl2O4S2YQVpstlWRbNzO0b2oYB1wMrZeYLEfFZ4EZg5cx8qpP3+RMwITP3Ll8HcC/wn8wc1tm9OrzH8hTLsqybmaPKtvOAjwLvUC7LEhHzUWTtDszM82by2Q6gCEJfBH6ZmZeXfUjgf4BlG0q6Ha89E1g9Mzfq7P3N8EmtMXipGf3bU1JPmzZlbFOXLJh0/Fe67Xd2nqMu7rXLLbRs4eXMHAn8GziqbPoL8DfgjxGxTUSsEBEbRsQPG7JvjwFbRMQmEfFR4DRghW7ozv9SjB98N8WSmW8CpwCnRMS+EbFyRKwREQeUY+zajQRWppiIMbKh7Ss0jN+LiMERcXpEDIuI5SNifWCT8u9AkiSpx7R6p42fAvtFxHJZpBq3BW4BzgYeBS4DVqFYqBmKWbP/pMgM3gZMAn77QTuRmc9TjCecu8Oh9pLzYcBDwE3A5ykyhO3XPgKMBx7LzJfL5pEU5fKRDe81HVgIOL/8bFcBd/L+iSuSJKmZajJLtyklXc05S7pSa1jSlVqj6SXdY3fvvpLusZdY0pUkSVJrNHOWriRJUu/Sy0ux3cWAT5Ik1Vcv3wO3u1jSlSRJqjgzfJIkqb4s6UqSJFVbXfbStaQrSZJUcWb4JElSfVnSlSRJqriaBHyWdCVJkirODJ8kSaqvmqzDZ8AnSZLqy5KuJEmSqsAMnyRJqq2sSYbPgE+SJNVXTQI+S7qSJEkVZ4ZPkiTVV022VjPgkyRJ9WVJV5IkSVVghk+SJNVXTTJ8BnySJKm2MusR8FnSlSRJqjgzfJIkqb5qUtI1wydJkuqrLbvvMQsRsWxE/DUi/h0RD0XEN8v2hSPipoh4vPxzobI9IuLUiHgiIu6PiLUa3mvv8vzHI2LvWd3bgE+SJKk5pgHfycxVgQ2AgyNiVeAI4ObMHArcXL4G2AYYWj6GA2dCESACxwDrA+sBx7QHiZ0x4JMkSbWVbdltj1neK3NcZt5TPn8TeBhYGtgJuKA87QJg5/L5TsCFWbgLWDAilgS2Am7KzAmZ+RpwE7D1zO7tGD5JklRfLRrDFxHLA2sC/wAWz8xx5aHxwOLl86WB5xsuG1O2ddbeKTN8kiRJ3SAihkfEqIbH8E7Omxe4Ajg0M99oPJbFOjHdHoWa4ZMkSfXVjVvpZuYIYMTMzomIgRTB3m8z88qy+cWIWDIzx5Ul25fK9rHAsg2XL1O2jQWGdWgfObP7muGTJEm11cwxfBERwDnAw5n5s4ZDVwPtM233Bv7Y0L5XOVt3A+D1svR7I7BlRCxUTtbYsmzrlBk+SZKk5tgY2BN4ICJGl21HAicBl0XEfsCzwJfKY9cB2wJPAJOBfQAyc0JE/Ai4uzzvuMycMLMbG/BJkqT6auKkjcy8A4hODm8xg/MTOLiT9zoXOLer9zbgkyRJ9dWNY/h6M8fwSZIkVZwZPkmSVFtdmWxRBQZ8kiSpvmpS0jXgkyRJtVWXDJ9j+CRJkirODJ8kSaovS7qSJEnVljUJ+CzpSpIkVZwZPkmSVF81yfAZ8EmSpNqypCtJkqRKMMMnSZLqqyYZPgM+SZJUW5Z0JUmSVAlm+CRJUm3VJcNnwCdJkmqrLgGfJV1JkqSKM8MnSZLqK6PVPWgKAz5JklRblnQlSZJUCWb4JElSbWWbJV1JkqRKs6QrSZKkSjDDJ0mSaiudpStJklRtlnQlSZJUCWb4JElSbTlLV5IkqeIyW92D5rCkK0mSVHFm+CRJUm1Z0pUkSaq42gd8ETH/zC7MzDe6vzuSJEnqbjPL8D0EJNAY+ra/TuDDPdgvSZKkHleXSRudBnyZuWwzOyJJktRsdSnpdmmWbkTsFhFHls+XiYi1e7ZbkiRJ6i6zDPgi4jRgc2DPsmkycFZPdkqSJKkZMqPbHr1ZV2bpbpSZa0XEvQCZOSEiBvVwvyRJknqce+m+Z2pE9KOYqEFELALU5K9HkiSp7+tKhu904ApgsYj4IfAl4Ic92itJkqQmaOvlpdjuMsuALzMvjIh/AZ8pm76YmQ/2bLckSZJ6Xm8fe9ddurrTRn9gKkVZ1/13JUmS+pCuzNL9AXAJsBSwDPC7iPh+T3dMkiSpp2VbdNujN+tKhm8vYM3MnAwQEScA9wIn9mTHJEmSelpddtroSnl2HO8PDAeUbZIkSeoDOs3wRcTPKcbsTQAeiogby9dbAnc3p3uSJEk9p7eXYrvLzEq67TNxHwKubWi/q+e6I0mS1Dy1X5YlM89pZkckSZLUM2Y5aSMiVgJOAFYF5m5vz8yP9GC/JEmSelxd1uHryqSN84HzgAC2AS4Dft+DfZIkSWqKzO579GZdCfiGZOaNAJn5ZGYeRRH4SZIkqQ/oyjp870REP+DJiDgAGAvM17PdkiRJ6nm1n7TR4FvAPMA3KMbyLQDs25OdkiRJaoa6jOGbZcCXmf8on74J7Nmz3ZEkSVJ3m9nCy1dRLLQ8Q5n5uR7pkSRJUpP09skW3WVmGb7TmtYLSZKkFqj9GL7MvLmZHdGMbbfmQa3uglRLr3zepUalOqjLGL6uLMsiSZKkPqwrs3QlSZIqqfYl3Y4iYq7MfKcnOyNJktRMNZmzMeuSbkSsFxEPAI+Xr1ePiF/1eM8kSZIqJiLOjYiXIuLBhrZjI2JsRIwuH9s2HPt+RDwREY9GxFYN7VuXbU9ExBGzum9XxvCdCmwPvAqQmfcBm8/Oh5MkSeqN2jK67dFF5wNbz6D955m5Rvm4DiAiVgV2A1YrrzkjIvpHRH/gdIqtblcFdi/P7VRXSrr9MvPZiPd9kOlduE6SJKlXa/Ys3cy8LSKW7+LpOwGXlkPqno6IJ4D1ymNPZOZTABFxaXnuvzt7o65k+J6PiPWALKPKQ4HHuthRSZKkWoiI4RExquExfDYuPyQi7i9LvguVbUsDzzecM6Zs66y9U10J+A4Evg18GHgR2KBskyRJ6tPauvGRmSMyc52Gx4guduNMYCVgDWAc8NPu+XTv6cpeui9R1I8lSZIqJWn9siyZ+WL784g4G7imfDkWWLbh1GXKNmbSPkOzDPjKG//XrOXMnJ00pSRJkmYgIpbMzHHly12A9hm8VwO/i4ifAUsBQ4F/AgEMjYgVKAK93YAvz+weXZm08ZeG53OXHXm+k3MlSZL6jLYmL8QXEZcAw4BFI2IMcAwwLCLWoEiwPQPsD5CZD0XEZRSTMaYBB2fm9PJ9DgFuBPoD52bmQzO7b1dKur/v0NGLgDtm58NJkiT1Rm1NLulm5u4zaD5nJuefAJwwg/brgOu6et852Ut3BWDxObhOkiRJLdCVMXyv8d4Yvn7ABGCWKzpLkiT1dr1h0kYzzDTgi2K15dV5b+ZHW2bWZds5SZJUcW2t7kCTzLSkWwZ312Xm9PJhsCdJktTHdGUM3+iIWLPHeyJJktRkSXTbozfrtKQbEQMycxqwJnB3RDwJTKJY+yUzc60m9VGSJKlH1KWkO7MxfP8E1gJ2bFJfJEmS1ANmFvAFQGY+2aS+SJIkNZUZPlgsIr7d2cHM/FkP9EeSJKlpevvYu+4ys4CvPzAv1ORvQpIkqaJmFvCNy8zjmtYTSZKkJmurSVprlmP4JEmSqqrZe+m2yszW4duiab2QJElSj+k0w5eZE5rZEUmSpGaryxZiM91LV5IkqcrqsixLV7ZWkyRJUh9mhk+SJNVWW9Rj0oYBnyRJqq26jOGzpCtJklRxZvgkSVJt1WXShgGfJEmqrbrstGFJV5IkqeLM8EmSpNqqy9ZqBnySJKm2nKUrSZKkSjDDJ0mSaqsukzYM+CRJUm3VZVkWS7qSJEkVZ4ZPkiTVVl0mbRjwSZKk2qrLGD5LupIkSRVnhk+SJNVWXSZtGPBJkqTaqkvAZ0lXkiSp4szwSZKk2sqaTNow4JMkSbVlSVeSJEmVYIZPkiTVVl0yfAZ8kiSptuqy04YlXUmSpIozwydJkmqrLlurGfBJkqTacgyfJElSxdUl4HMMnyRJUsWZ4ZMkSbVVl1m6BnySJKm26jJpw5KuJElSxZnhkyRJtVWXSRsGfJIkqbbqMobPkq4kSVLFmeGTJEm11VaTHJ8BnyRJqq26jOGzpCtJklRxZvgkSVJt1aOga8AnSZJqzJKuJEmSKsEMnyRJqq26bK1mwCdJkmqrLsuyWNKVJEmqOAM+SZJUW9mNj66IiHMj4qWIeLChbeGIuCkiHi//XKhsj4g4NSKeiIj7I2Kthmv2Ls9/PCL2ntV9DfgkSVJttXXjo4vOB7bu0HYEcHNmDgVuLl8DbAMMLR/DgTOhCBCBY4D1gfWAY9qDxM4Y8EmSJDVJZt4GTOjQvBNwQfn8AmDnhvYLs3AXsGBELAlsBdyUmRMy8zXgJv47iHwfJ21IkqTa6iWTNhbPzHHl8/HA4uXzpYHnG84bU7Z11t4pM3ySJKm2unMMX0QMj4hRDY/hs92fzNkZEthlZvgkSZK6QWaOAEbMwaUvRsSSmTmuLNm+VLaPBZZtOG+Zsm0sMKxD+8iZ3cAMnyRJqq0WTNqYkauB9pm2ewN/bGjfq5ytuwHweln6vRHYMiIWKidrbFm2dcoMnyRJqq1mj+GLiEsosnOLRsQYitm2JwGXRcR+wLPAl8rTrwO2BZ4AJgP7AGTmhIj4EXB3ed5xmdlxIsj7GPBJkiQ1SWbu3smhLWZwbgIHd/I+5wLndvW+BnySJKm2esUc3SYw4JMkSbX1Acfe9RlO2pAkSao4M3ySJKm2siZFXQM+SZJUW5Z0JUmSVAlm+CRJUm31kr10e5wBnyRJqq16hHuWdCVJkiqv1wZ8EbFyRGRErNHqvkiSpGpqI7vt0Zv1WEk3Is7nvY2AG62ZmaN76r6zEhF3ABsDX87MSxravwqckpkLtqpv6nvmmX8evn3yoSy/yvJkJj897Ofs8tWdWXbFZcrj8zLpjYkcuHWxM85uB+/KVrttRdv0Ns445kz+deu/Wtl9qc8YvP/hDFxzA/KN//Dm4fsC0O/DKzFkv28Rcw+m7eXxTDr9BHhrcnlsRYbs921iyDzQ1sabRx0AU6cycIPNmXuXPaBff6becydvXzKilR9LvUBdZun29Bi+vwB7dmh7pYfv2RVvA8dHxBWZOaXVnVHfddCxB3D3yH/xowNOYMDAAcw1eC5+fNCJ7x4ffvTXmPTGJAA+PPTDbLbjZgzfYn8WWXxhTrrkRPbd9Ku0tdXlPzfSnJty6w1MufEqhhz0/Xfbhgw/jLd+exbTH76PQcO2Ye7td+Xty8+Dfv2Y5+AjmXT6ibQ99yQx7/wwbTox7/wM3mN/3jxyf/LN1xly4BEMWG0tpj10Tws/mdQcPV3SfSczx3d4TAOIiG0j4o6I+E9ETIiI6yNilc7eKCL6RcRZEfFkRKxUti0YEb+JiJci4o2IGBkRa3WhX5cA8wMHzOykiNgkIm6PiLciYkxEnB4R85XHti/73r98/dGyBH1aw/UnRcQN5fNBEXFaRIyLiHci4vmIOKELfVUvNWS+IXxi/U9ww6U3ADBt6rR3g7t2m22/KX/940gANtpyQ269+lamTpnK+Odf5IVnxrHKGp3+X15Sg+mP3E9OfON9bf2XXIbpD98HwNT7RzFwvU0BGPDJdZn+3FO0PfckQHFdttHvQ0syffxY8s3Xi2se+BcD19+0iZ9CvVF24/96s1aO4ZsH+CmwLrA5MBm4OiIGdjwxIgYBvwc2AjbJzCcjoh9wPfAhYFtgbeDvwC0Rsfgs7v0G8CPg6IiYf0YnlGMHbwSuAD4JfAFYBzi7POV2YF5gzfL1MIrs5bCGtxkGjCyffwvYAfgS8BFgN+DxWfRTvdgSyy7Bfya8zmE/+w5nXH8a3zr5UOYePNe7xz+x/sd57ZXXeOGZFwBYZIlFePmFl989/sq4V1h0iUWa3m+pKqaPeYaB62wMwKANhtFvkQ8BRSBIJvMccTLz/vjXzLXDbgC0vTiW/ksuS79FF4d+/Ri4zib0W3ixlvVfvUNbNz56s54O+LaOiIkNj+vbD2Tm5Zl5VWY+npn3AfsAQykCt0bzAtcCSwGbZea4sv0zwKrAFzNzVPk+RwJjgD260LezKAK/wzs5fjhwcWb+onzvu4CDgV0jYuHMfB0YTRGsQhHcnQqsHBGLRcS85WcZWR5fDngUuCMzn83Mv2Xm+TO6cUQMj4hRETFqzMTnu/BR1Ar9B/Rn6MdX5poLr+GgbQ7h7clvs+vBu757fNhOw97N7knqfpN/fTKDPrsT857waxg8mJw2tTjQrz/9V/kEk08/nonHfoOB62zCgNXWIidNZPK5P2fIN49h3mNOpe2V8eCQCtVET4/huw0Y3vD6rfYnETEUOA5YH1iUIvgM4MPAXQ3XXEIRxG2RmZMb2temCAZfjYjGe84NrDSrjmXmlIg4CvhNRJw+g1PWBpaPiMbgsf1GKwETKIK5YcBPgM2Ak4GtyrY3KcYKjiqvOY8iY/hoRNwIXAfcmJn/9V+bzBwBjADYctmte3eOuMZeGfcKL497hUdGPwrA7dfdzq4HFQFfv/792GTrjTl426+/e/6r419lsaXeyyYsuuSivDL+1eZ2WqqQtheeZ9KJxb/Z+y2xDAPX2KBon/ByUQJ+sygBTx39D/qvMJRpD93DtHvuZOI9dwIw6NPbG/Cp15diu0tPZ/gmZ+YTDY+xDceuBRYGvkYR9K1NkREd1OE9rqUoqW7Yob0fMA5Yo8Pjo8CxXezfpcAjnZzfD/h1h/denSIL+UB5zkjgUxHxcYpAc3TZtjlF0Pe39jGLmXk3sDxwFDAQuBi4PjpEq+o7Xnv5NV4e9zLLlDNy19x4TZ57/DkA1vrUmjz/5PO8Mv69OUp33nQXm+24GQMHDWSJZRdn6eWX4tEyWJQ0+2L+clGFCObeZU+m3PwnAKbdfzf9ll0BBs0F/fox4GOrM33ss++7JuaZl7k+uxNTbrm2JX1X71GXkm5Ldtoox9gNBfbLzNvLtvWYcQB6FnA/xfi+HTLzlrL9HmAJYFpmPjMn/cjMjIjDKTJvb3Y4fA+wamY+MZO3uB0YAnwHuC0z2yJiJPAr4HXg/zrc7w3gMuCyiLgIuANYAXhqTvqv1jv96DM44leHM2DgQMY/N45TvpVtwncAABf9SURBVPMzAIbt+N/l3Gcfe5bbrrmNs2/5NdOntXHaUac7Q1fqoiFfP4oBH1uDmG8B5j/tMt7+w/kw92Dm2nInAKb+83amjCxGDeWkibxz3eXMd8JZkMnU0f9g2r1F4Wjw3ofQ/8NFEejtKy+kbfyYlnweqdkis2dSmeU6fItm5vYzONYfeImirPlDYBmKsuhawN6ZeXFErEwxqWHNzBwdEQdTlEx3yMxbykkbd1AEXN+jGB+3JLANcENm/r2Tft0BjMrMQxvabqAoyb7Tvg5fOWnjTuBciokaE4GPAdtl5gEN146iyPx9NzN/ERFDgNeA/hQTTO4qzzuMojQ9GpgOfBP4CrBEZr7d2d+jJV2pNS7b5J1Wd0GqpQUv+WtTK197Lve5bvudvejZK3tt1a4ls3QzczqwK0WA9yBFRuz7wNSZXHM6RWD3p4j4dDn2bWuKLNu5wGMU2bOhFKXe2fE9OpSSy8WhNyvf73aKQO2EGbz3SIpM6cjyusnA3RTjFUc1nDexvM+o8vFxYOuZBXuSJKlnZTc+erMey/Cpe5jhk1rDDJ/UGs3O8H2lGzN8F/fiDF9LxvBJkiT1Br19D9zuYsAnSZJqy2VZJEmSVAlm+CRJUm3VZXEsAz5JklRbdRnDZ0lXkiSp4szwSZKk2qrLpA0DPkmSVFuO4ZMkSaq4umxA4Rg+SZKkijPDJ0mSaqsus3QN+CRJUm3VZQyfJV1JkqSKM8MnSZJqy2VZJEmSKq4uY/gs6UqSJFWcGT5JklRbdVmHz4BPkiTVlrN0JUmSVAlm+CRJUm05S1eSJKninKUrSZKkSjDDJ0mSastZupIkSRVnSVeSJEmVYIZPkiTVlrN0JUmSKq6tJmP4LOlKkiRVnBk+SZJUW/XI7xnwSZKkGnOWriRJkirBDJ8kSaqtumT4DPgkSVJt1WWnDUu6kiRJFWeGT5Ik1ZYlXUmSpIqry04blnQlSZIqzgyfJEmqLSdtSJIkVVwb2W2ProiIZyLigYgYHRGjyraFI+KmiHi8/HOhsj0i4tSIeCIi7o+Iteb0cxrwSZIkNdfmmblGZq5Tvj4CuDkzhwI3l68BtgGGlo/hwJlzekMDPkmSVFuZ2W2PD2An4ILy+QXAzg3tF2bhLmDBiFhyTm5gwCdJkmqr2SVdIIE/R8S/ImJ42bZ4Zo4rn48HFi+fLw0833DtmLJttjlpQ5IkqRuUAdzwhqYRmTmiw2mbZObYiPgQcFNEPNJ4MDMzIrp9JokBnyRJqq3uXIevDO46Bngdzxlb/vlSRFwFrAe8GBFLZua4smT7Unn6WGDZhsuXKdtmmyVdSZJUW22Z3faYlYiYJyLma38ObAk8CFwN7F2etjfwx/L51cBe5WzdDYDXG0q/s8UMnyRJUnMsDlwVEVDEYL/LzBsi4m7gsojYD3gW+FJ5/nXAtsATwGRgnzm9sQGfJEmqrWZurZaZTwGrz6D9VWCLGbQncHB33NuAT5Ik1VZXSrFV4Bg+SZKkijPDJ0mSaquZJd1WMuCTJEm1ZUlXkiRJlWCGT5Ik1ZYlXUmSpIqzpCtJkqRKMMMnSZJqy5KuJElSxWW2tboLTWFJV5IkqeLM8EmSpNpqs6QrSZJUbeksXUmSJFWBGT5JklRblnQlSZIqri4lXQM+SZJUW+60IUmSpEowwydJkmrLnTYkSZIqri5j+CzpSpIkVZwZPkmSVFsuyyJJklRxlnQlSZJUCWb4JElSbdVlHT4DPkmSVFuWdCVJklQJZvgkSVJtOUtXkiSp4izpSpIkqRLM8EmSpNpylq4kSVLFZU3G8FnSlSRJqjgzfJIkqbYs6UqSJFWcs3QlSZJUCWb4JElSbdVl0oYBnyRJqi1LupIkSaoEM3ySJKm26pLhM+CTJEm1VY9wD6Iuka3UChExPDNHtLofUt343ZPezzF8Us8a3uoOSDXld09qYMAnSZJUcQZ8kiRJFWfAJ/UsxxBJreF3T2rgpA1JkqSKM8MnSZJUcQZ8kiRJFWfAJ0mSVHEGfJIkSRVnwCfNhoiI8s8VI+LDre6PVBcN370FW90XqS8y4JO6KCIiMzMidgauAz4bEYu2ul9S1TV897YGTo+IT7e6T1JfY8AndVH5g7MD8Fvg18B1mflKi7slVV753fs8cCXwADAB3sv6SZo11+GTuigiFqbI7F2dmT+OiLmA+YGtgQmZeW1LOyhVVER8guK7d2xmntPQvmpm/rt1PZP6jgGt7oDUh0wDAni2HL+3P7AhsBYwJiLWyswftbKDUkUtB7wBnB8RA4G9gS8Dq0fEbZm5S0t7J/UBlnSlWYiItctg7g1gInAs8BCwCnAJ8DHgUWDplnVSqqCIWLl8+iLF79WFwF3A9sD9wG7AThGxZ2t6KPUdZvikTpTjgwYA51MEdF/IzC0i4n+At4D/A6ZmZltETAKmR0Q/iiFHjpWQPoCIWB64KCJ+AlwNnAFsBPwFuCAz/x0Rg4DbAcfSSrPgGD6pg/YZgQ2vNwSuB76bmWd3OHdB4HDgAGDjzHy4qZ2VKioilgVGAM9l5v7lP6YGZOaUhnN+SFHe3Swzn21RV6U+wYBPmoEyyJsKPJ6Zr0fEScAngMPag7pyeZavA8sCu2bmvS3rsNTHNSy9sizwn8x8MyI2BW4B9snMixrO3Q7YEfgcsKXfPWnWHMMndRARSwM3UpRsj42I1YCzKMbofarh1GuBy4Gt/cGRPpgy2NuIYvjEuRGxYmbeBhwJHBERawKUkzaWBxLY1O+e1DVm+KQOyjLtr4D1gQuAbwNfAbYE9gTWysznWtdDqVoasnsfB26gmA3fjyLYm0Lx3Xsc+EVmToyI/sBcmTm5ZZ2W+hgDPqkUESsB72TmmIj4CPBP4FDgBeBkitmBw4GrgL0zc2LLOitVSET0z8zpETEP8H3gTYqJURsBbcB6FDN198rMJ1vXU6nvsqQrUeyNC5wLXBIRG2fmY8AhwK7AveWfT1Gs8L8hMKhVfZWqJCLWBR6KiA0zcxJwKcUal4+Wf14HTKf43v2kZR2V+jgDPgnIzKeAnwL/Bm6NiB9QjBF6CtgxMx8FTgXWpJiNO6FlnZUqoJx1CzCJYl3LKyPiZ8Bk4CCKGbpLZubFwOYU2xn+oBV9larAkq5qqWHM0GLAAsA4YHLZth9F6fYFYHXgVYqgb1zreixVQ8N3b0BmTmto3w/YlmLnmouAZYDngFPKcXvvWy5J0uwx4FPtNPzg7AwcQfHD8ijwDHBwZr4dEWsAn6ZY4+sTFAu97tOqPktV0PDd24Jia7T5gdeAb5TfuxWALShKt4MpdrbZqBxiIekDsKSr2il/cLYEfgv8jmJg+G3APsAXynNGA6dRrPV1BcWkDUkfQPnd24ViyaOJFN+7bYG/R8Timfl0Zv6GIsv3B4py79SWdViqEDN8qrTGMlC5VVoA/YEzgXGZeXRZ1r0HuCozv9HxOklzZga71ixOsezKhZn584hYArgbuCYzD+xw7XwUO2u81tROSxVlhk+V1ThOr8weZGa2ZeZUikWUH4uIZShm4V7XEOztBOzQwq5LfVrDhIwoX7fv2z4EmBs4IyKWAkYB17YHexGxfft7ZOabBntS9zHgU2WVwd4iFLthHFtmE4iIuSkWc92eoqR0XWbuXx6bH9gZGNrwIyVpNmRmW7lF2h0RsWRmTisz7G+Vjy8DfweuodiekIhYDjioHN8nqZsZ8KnSMvNV4B/AOsB3ImLpzHwbOIli9f63gPbsQgDfA4YBf2ycQShpti1FMSnjxvYMOzANeJ5iSMW/MvOAMuMOcACwGPBwS3orVZxj+FQpZdDWnt0b2P5jEhHHUGTu/gL8stxNYx+Ktb5upljZfxpFEPgZ9+eUPriI2JjiH1eLAp/OzHERsSHFhKnHgKspAsCtgT2AzTLzvlb1V6oyAz5VRkT0K0tJi2Tmq+3bNTUcPw7YCfgzxdpeL5ar/B9IMa7oceB35SLLkrqo4bvXH2jrMFHqU8CJwCIUQd8LEbEpRSl3A4plWcYDh2Xm/a35BFL1GfCpUso9cB+hKOM+AVwIvJCZD5XHvw3sSzFT8NTMfK49E+jMXGnORcRHKda1fIZiuaPJmTmmPLYuxU41iwCbZ+bY9lm4FDvaTMnMyS3puFQTBnyqlHKG7VXAG8BfKfbffBt4kCLIuwL4LvBxitm5p2bm2PJaAz5pDkTEYOAmijUtpwJjKcbH3gTcSbHu3sbAocBHgE0z86X2zGBrei3ViwGfKicidqUYI/Rdih+cxSm2SvsIxaDwpyhKSQGcABznj470wUTEVsBxFBn2J4AnKSZirEixyPLTFOP1vgC8AmzgntRS87jshConM39flot+DfwoM4+lmJhBucr/h4B5KLZuutRgT5pz7ZnxzLwxIgYBR/Hed+t35VJHewErA58D5gMWpNjD2oBPahIzfOrTOk7M6HBsP4pZuCcAJ2TmOw3HFgDIzNeb0lGpwjrsaLMdRabvaYoZ8bc3nLckxTi+iZn5TCv6KtWVGT71SeVeuH/LzEmdjQPKzHMiIoGzgbaI+HFmTimPGehJ3aRcBqk903dt+b07Dvh62XxHeer4zBzXwq5KtWXApz4nIjYBTgduiojDMnPyTIK+c8ulIU4HhkTEkS6oLHW/DkHfdeWSmMcBB0fEgMwc6aQoqXXcaUN90SiKSRlrAv8vIoaUa4DN8P/PmXkO8B2K5VgWbF43pepr/N61B33l8+uAo4F1gb3LmbySWsQxfOpTGhZ4nQs4HNiBYs29780s01deu4ClXGnOtWfwImJhigrRhPaMeYdxfI3PPws8kZlPt6zjkgz41Pe0T9Qog77vAdvTxaBP0pxpCPZ2pJiJOz/FWnuXARe1L7Lc8fwWdFXSDFjSVZ/TPiu3nHV7MnAtsD5dKO9KmjNlsLcVxS4alwObU/xD6/sUwyv+6/zm9lDSzJjhU5/QkF0YCnyYYuHWFzNzfDk26HBgO8z0Sd2u/AdUf+Ai4JnMPCIiFgPuAm7MzIPK8wZm5tQWdlVSJ8yCqNdrCPY+R7FzxpnAH4BfRMR6mfkW72X61gZOj4jBBntS98jMtjKQWwK4oRzDNxr4S0OwtzOwRgu7KWkmDPjU65XB3meBc4BTMvMjwCnA1sApEbFJQ9B3B0UGcIGWdViqkIhYtRwvC/AOxZaFd1Psj3tIec48wFeATRxOIfVOlnTV65VbM40AHs/MoyNiKeBvwKMU2zQBfCsz/xkRcwPzZuYrLequ1Gd13LkmIj4O3AhskplPl2P4zgTezsxVG847Adgd+GxmPtnsfkuaNf8lpl4vM9+gCPiuiIiFgBsoSklbA5cA6wDnlpm+tw32pNkXEYcD55X/aGo3H/AG8Fz5+h/Ab4D5IuKWiDgtIn4PHAh83mBP6r0M+NRXjMzM0cCOFBuu/6Bsfx64l2Lw+PMt6ptUBU8CX6YYJjGkbFuIIpvXPjP+P8AZwN7Af4ClgTHAhpl5b/O7LKmr3FpNvUrDBI11gOWB5YArgRcoxg8tWLYtALwEbADcBvy4/DGSNAcy84qI2IliQlQ/4CBgbuB9iymX37NbyoekPsKAT71KGex9HjiLIms3FNgDuDoifgQ8QRHoXRwRrwKbAusb7EkfXGZeGxFfBC6PiDcoZuJOiojNgLaIeBkYDKwIjMrMZ11gWeobDPjUq0TEmsBpwOGZeV5ELAc8DVxelpWujYgFgPUosnzrZea/W9djqe9rDNoy85qI2BX4PTCN4h9Y5wFDKMq48wADKbLrLrAs9RHO0lWvUmb3DsnMzSNiFd6boPG18vjSmTm2fP6+GYWSZk/DEIr5ADLzzYZj7ZOi/gp8A3gbmEIR7E1zX2qpb3HShppuRut0RcTA8ulKwFsRMYBikeU/A/uX52wDfC0iFoT3tliTNPsagr1tgauB2yLitohYOyLmyswbgD0pdrA5DHgzM9/IzFcN9qS+x4BPTdW+3VlEfCgi1o2IYQAN2zFdB2wETAKuzMz9G3bM2BpYi3IQuaQ50xDs7QhcCvwdOJQie/cbYJsy6LsG+AJFhu+EiIiWdVrSB+IYPjVNQ7D3CeBCYH5ggYgYVa6pB8V4vV8Cw4Hx5XUrAV+lyDZ8yuyCNHsavnvtM22z/F4dAxydmb8st0tbgmKM3lnAARFxY2b+KSK2A552vJ7Ud5nhU1M0/OCsDtxJUardFTgR2DIiTgTIzEnAxcDZwP9GxFiKLZx2BrbIzIda8gGkPqrhu7cWcHzDNmlzAZcDIyJiSYpFla/LzA9RrK13DLBTmem7PjMfackHkNQtnLShpomIlYEHKPbDPbpsWxR4hOKHZq+GcwcDy1CUd5+m2FZtXPN7LfVdDcHeJ4F7gF9k5mENx4dm5uMRcRawMLBvZk6MiIspFmF+iGJR5Ykt+QCSuo0lXTVFOVFjX4qxeY1r5u1H8UPzkYg4umw7G5icmY8Djze1o1JFzCCr/v8y8weN55TBXlAscj6qIbB7CVgfGGewJ1WDAZ+aovzh+RXFWl67RcQ75fPDgSOB+4GtKH5k9gcmR8RJmXluq/os9WXld25ligXMT8nMoxuCwP2AZzLz5nI8H8D2EfEIxfp6XwF+npljWvcJJHUnAz41TWaOi4iTKPbB/TrFav1bZWb7Fk3Xwbtr8a1LMaZI0hyYUVa9DPZ+QDEjd8eG0/cArqf4bk4FhmWme1NLFeIYPjVdRCxOkdX7NHBRZp5cts+Vme+Uz92uSfqAyskY3wM2Bi6g2BbtcGCvzLy+POfd71p5/mRnwkvVY8CnloiIJSiyCRsAV2Xmj8t2d8+QulHDd21LGrLqjd+19lJvK/spqWe5LItaIjPHAydQjC/aISKOL9sN9qRuVH7XjqfYpvARYJ2yfXpE9C+fG+xJFWfAp5ZpCPoeATaKiEVa3CWpkjLzRYo1L0cCX4yII8v26TPa6lBS9VjSVcuVY/raf5Qk9ZCG8u46wM2ZeVSLuySpSQz4JKlGyqDvRGA54IuZ+WqLuySpCQz4JKlmzKpL9WPAJ0mSVHEO1pUkSao4Az5JkqSKM+CTJEmqOAM+SZKkijPgkyRJqjgDPkm9QkRMj4jREfFgRFweEUM+wHsNi4hryuc7RsQRMzl3wYg4aA7ucWxEHNbV9g7nnB8RX5iNey0fEQ/Obh8lqZ0Bn6Te4q3MXCMzPw5MAQ5oPBiF2f5vVmZenZknzeSUBYHZDvgkqS8x4JPUG90OrFxmth6NiAuBB4FlI2LLiLgzIu4pM4HzAkTE1hHxSETcA3yu/Y0i4n8i4rTy+eIRcVVE3Fc+NgJOAlYqs4s/Kc/7bkTcHRH3R8QPG97rBxHxWETcAawyqw8REV8r3+e+iLiiQ9byMxExqny/7cvz+0fETxruvf8H/YuUJDDgk9TLRMQAYBvggbJpKHBGZq4GTAKOAj6TmWsBo4BvR8TcwNnADsDawBKdvP2pwK2ZuTqwFvAQcATwZJld/G5EbFnecz1gDWDtiNg0ItYGdivbtgXW7cLHuTIz1y3v9zCwX8Ox5ct7bAecVX6G/YDXM3Pd8v2/FhErdOE+kjRTA1rdAUkqDY6I0eXz24FzgKWAZzPzrrJ9A2BV4G8RATAIuBP4KPB0Zj4OEBEXA8NncI9PA3sBZOZ04PWIWKjDOVuWj3vL1/NSBIDzAVdl5uTyHld34TN9PCKOpygbzwvc2HDsssxsAx6PiKfKz7Al8MmG8X0LlPd+rAv3kqROGfBJ6i3eysw1GhvKoG5SYxNwU2bu3uG89133AQVwYmb+usM9Dp2D9zof2Dkz74uI/wGGNRzruK9llvf+emY2BoZExPJzcG9JepclXUl9yV3AxhGxMkBEzBMRHwEeAZaPiJXK83bv5PqbgQPLa/tHxALAmxTZu3Y3Avs2jA1cOiI+BNwG7BwRgyNiPory8azMB4yLiIHAHh2OfTEi+pV9XhF4tLz3geX5RMRHImKeLtxHkmbKDJ+kPiMzXy4zZZdExFxl81GZ+VhEDAeujYjJFCXh+WbwFt8ERkTEfsB04MDMvDMi/lYue3J9OY7vY8CdZYZxIvCVzLwnIn4P3Ae8BNzdhS4fDfwDeLn8s7FPzwH/BOYHDsjMtyPiNxRj++6J4uYvAzt37W9HkjoXmR2rCpIkSaoSS7qSJEkVZ8AnSZJUcQZ8kiRJFWfAJ0mSVHEGfJIkSRVnwCdJklRxBnySJEkVZ8AnSZJUcf8fArJACXbq9QIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# figsize = (10,7)\n",
    "# fontsize=14\n",
    "# df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "# fig = plt.figure(figsize=figsize)\n",
    "# heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "# heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "# heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "# bottom, top = heatmap.get_ylim()\n",
    "# heatmap.set_ylim(bottom + 0.5, top - 0.5)\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.set(font_scale=1.4)\n",
    "# sns.heatmap(cm, square=True, annot=True, cmap='RdBu', cbar=False, annot_kws={\"size\": 16})\n",
    "# plt.xlabel('Real values')\n",
    "# plt.ylabel('prediction')\n",
    "# # plt.ticklabel_format(useOffset=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
